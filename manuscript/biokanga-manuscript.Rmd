---
title: 'A fully reproducible and extensible evaluation framework for RNA- and DNA-Seq aligners and assessment of biokanga - a general purpose bioinformatics toolkit'
author:
- Author First (University of Foo)
- Another Person (University of Bar)
output:
  bookdown::pdf_document2:
    number_sections: yes
    toc: false
    # keep_tex: yes #if needed for final submission
abstract:
  This is the abstract.
bibliography: references.bib
csl: elsevier-harvard.csl
link-citations: true
urlcolor: blue
linkcolor: red
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.path = "figures/"
)
```


# ideas/stubs
- good enough practices paper
- Sandve GK, Nekrutenko A, Taylor J, Hovig E. Ten Simple Rules for Reproducible Computational Research. PLoS Comput Biol. 2013;9(10). pmid:24204232
- Brett K Beaulieu-Jones & Casey S Greene Reproducibility of computational workflows is automated using continuous analysis
- [Developing a modern data workflow for regularly updated data](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000125)
- [Practical Computational Reproducibility in the Life Sciences](https://doi.org/10.1016/j.cels.2018.03.014)
- [Methods for enhancing the reproducibility of biomedical research findings using electronic health records](https://doi.org/10.1186/s13040-017-0151-7)
- [Systematic benchmarking of omics computational tools](https://www.nature.com/articles/s41467-019-09406-4) - a Review
- [Critical Assessment of Metagenome Interpretation - a benchmark of metagenomics software](https://www.nature.com/articles/nmeth.4458) - with containers and Zenodo
- [Terminologies for Reproducible Research](https://arxiv.org/pdf/1802.03311.pdf)
- [Benchmarking comes of age](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1846-5)
  - ["Du√≤ and Soneson made available data and software for adding new clustering algorithms directly to existing figures "](https://bioconductor.org/packages/release/data/experiment/vignettes/DuoClustering2018/inst/doc/plot_performance.html)
  - [Reproducible biomedical benchmarking in the cloud: lessons from crowd-sourced data challenges](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1794-0)
# Introduction

- Why does computational reproducibility matter? Point to refs, needs to very brief
- Value in reproducibility for analysis generally, and benchmarking
- Challenges around reproducibility/recomputability in computational biology. Usually more than one tool make things hard. Greater complexity and computation intensiveness increases these challenges.
- Beyond these challenges, how can we make work extensible and reusable?

### key concepts

- Using thinking around devops (CA paper) can leverage improvements from software engineering for research/analytical code to make it deployable and reusable
- Key concepts:
  + code under git version control system with well-defined use of git and GitHub functions and features to address some of the challenges listed above
  + environment/dependencies
  + building/exposing containers - Docker, Singularity [@Kurtzer2017]
  + tracking releases and linking to artefacts
  + minting of DOIs for code, output and execution metadata
  + workflow management
    + description of workflow in a standard way
    + sharing of workflow - can be re-run by others with minimal effort
    + separation of pipeline logic from execution environment - (potential for) portability across execution environments
    + scalability "for free" through implicit parallelisation - independent tasks will be executed separately if resources available

### This work
- In an effort to demonstrate a framework that implements these principles of reprocomputability, extensibility and transparency, we chose to implement an entirely existing toolset in the context of previously published work, in an effort to highlight the fact that the technology and support already exists to make these practices the norm - the challenge is orchestrating the range of tools to enable a complete solution. We have chosen the space of DNA/RNA aligner benchmarking so that we can illustrate these approaches in the description of the BioKanga suite of tools, specifically its aligner.

### Previous work
Previous efforts related to aligner benchmarking published a code repository making it technically possible to reproduce the analysis, however several factors meant that it was challenging to extend and reuse.
Even though versions of the required software were specifically stated, re-running of the analysis would require downloading and installing all the required software tools (assuming they are availiable).
Furthermore, the original analyses were carried out in specific directory structure which could not be reproduced on another system by an unprivileged user.
The alternative would be to laboriously edit the multitude of hard-coded paths while not being able to test the code until sufficient changes have been made to make it functional again.

### biokanga align
- Introduce biokanga

# Methods

Our approach relies on several key systems used in concert.
Use of GitHub offers much more than version control as it offers programmatically accessible spaces
for other systems to/from which deposit/retrieve information.

## Scalability

* NF implicit parallelization
* Flexible - will make good use of resources whether on a single multi-core machine or a cluster of thin nodes

## Extensibility

Additional aligners can easily be included in and evaluated by the workflow.
This is facilitated by the pipeline's modular design, the main script which describes
the pipeline logic remains unchanged and addition of an aligner is done through
inclusion of a simple genome indexing template and one or two alignment templates
depending on whether the tool can be configured to align both DNA- and RNA-Seq
reads.
The final addition is that of a dedicated container image
as we outline in the [next section](#Building-and-exposing-containers).





## reproducibility practices


### Building and exposing containers

A single container image capturing the software environment for a workflow should suffice in most cases.
For some workflows however, it may be preferable to have a separate container image for each tool.
In the case of our workflow, this enables easy addition and benchmarking of a new tool
while the rest of the workflow remains unaffected, with the exception of some downstream processes
which aggregate data produced by all of the evaluated tools.
Such processes have to be re-run on addition of a new tool e.g. to visualise the updated results.
Having a separate container per tool or perhaps per branch of the workflow may also be advantageous
for computationally intensive or long-running workflows as this approach limits the need to
re-run the entire pipeline or its substantial parts due to global software environment being modified.

Meaningful benchmarking requires precise traceability of each evaluated software tool.
The minimum is the stating of the version of the tool being used and perhaps providing
the appropriate binary executable.
More broadly, reproducibility of computational analyses demands that we not only capture
the version of a given tool but the entire software environment.
To address this and the additional goals of reusability and extensibility,
we propose procedures for building, distributing and using the containers.

For a handful of benchmarked tools we rely on containers from BioContainers collection.
For most of the remaining tools however, we provide a dedicated Docker Hub repositories.
Each repository is configured to automatically build a version of the container
for a tool, given an appropriate trigger in our workflow's GitHub repository.

Additional docker container images are provided with auxiliary tools required for benchmarking,
including, but not limited to the RNA-seq benchmarking toolkit [@Baruzzo2016] (modified in https://github.com/rsuchecki/biokanga_benchmark)
and the DNA-seq benchmarking toolkit [@Brinda2015] (builds automated as for benchmarked tools).

The procedure for adding or updating individual container images
involves creating or updating an existing `tool.Dockerfile` (e.g. `samtools.Dockerfile`)
on a dedicated a dedicated `tool/version` branch in the main repository, for example `samtools/1.9`.
Changes committed to that branch are captured in a container image in the associated Docker Hub repository.
This is done through an automated build triggered by code being push to that branch on GitHub.
The generated container image is tagged with the version specified in the git branch name.
Since a container image captures more than just the primary tool of interest, the tool version tag
is not sufficient from reproducibility perspective.
A container image may have to be re-created for a number of reasons other than version change of the main tool.
An underlying base image may need to be patched or an auxiliary tool may have to be added to the container
to facilitate its use within a workflow e.g. to aid collection of execution statistics.
In such case the version tag remains unchanged even though the underlying container image has been replaced.
We provide automation code (a "`post_push` hook") which ensures that in addition to the container image version tag,
which may potentially be overwritten,
additional tags based on git commit SHA hash are generated.
These effectively permanent tags are then used when referencing a container in workflow configuration files.
For example, rather than pointing to `1.9` tag in our `samtools` Docker Hub repository we point to `1.9_ea5d3c82fb85c174dce08a4c736ed44c1e6bb7eb`.
The permanence of such created container images relies on the procedure being followed.


Our workflow can be run with either Docker or Singularity
with the later relying on conversion of Docker container images to its own format.
This conversion is said not to be fully reproducible,
but this is apparently due to potential for the layers underlying a Docker container image being changed.
Since we ensure the stability of our container images, this should not be an issue.
If we were to use Singularity directly,
we would opt for providing and maintaining Singularity container images
on Singularity Hub as the means for insuring the stability of the containers used.
We provide an example of how this can be achieved
in [https://github.com/rsuchecki/miniconda3](https://github.com/rsuchecki/miniconda3).
Briefly, for a given software tool a repository needs to be created on Singularity Hub
and linked to a GitHub repository containing the recipe for creating the container image.
With the already available Docker container image, it suffices
for the corresponding Singularity recipe to simply point
to the Docker container image as its source.
Building of the container image is triggered by changes made to the GitHub repository
and a fixed version of the container image remains available from Singularity Hub.
Functionality and flexibility of Singularity Hub is currently somewhat limited
as compared to Docker registries which makes it less suited for the type of work
we present here. For a project relying on fewer containers it could already be
an equally good and potentially a superior solution, given for example,
the ability to easily freeze a container image build/tag, to ensure it will not overwritten.
Furthermore, as commercial cloud providers integrate Singularity into their services
([https://azure.microsoft.com/en-au/blog/azure-container-registry-now-supports-singularity-image-format-containers/](https://azure.microsoft.com/en-au/blog/azure-container-registry-now-supports-singularity-image-format-containers/))
the benefits of this container format designed for reproducibility [@Kurtzer2017]
may outweigh its current practical limitations.

Docker v2 specification provides another solution of addressing the problem
of container image identity and to en extent its persistence
via [content digests](https://docs.docker.com/registry/spec/api/#content-digests).
A digest contains a SHA-256 collision-resistant hash of the content of an image.
Implemented by Docker registries such as Docker Hub or Quay,
a digest is returned when an image is pushed to a repository.
The digest can later be used to pull this exact version of the container image.
We use this functionality to reference the BioContainer images.
For example
`quay.io/biocontainers/subread@sha256:a27dcc4f335d8f98346a9b9d886230de6bba2bf7518372c2022c22ab225c09ff`.
Our container images hosted on DockerHub can be accessed in the same fashion.
However, specification of a container image is clearer if a tag containing the version number is used,
so syntax which includes both the version tag and the digest hash (`repository:tag@digest`)
is optimal as the image is only pulled if the specified digest hash matches the one in the registry.
Our workflow is compatible with this syntax, but Singularity currently (as of version 3.1.1) does not support it.
Since we already have a mechanism for ensuring permanence of container images we opt for
not applying this approach to maintain the portability of the workflow - unlike Docker,
Singularity is commonly available on HPC clusters.
One limitation of Docker Hub is that digests are not easily accessible
without either authentication or simply pulling an image container and re-computing its digest.
This can be circumvented, at the some cost to readability, by embedding the digest hash
in another tag pushed to Docker Hub.








### Capturing code and associated results under DOIs

A particular revision of code in a  git repository
can be tagged to clearly identify a version which may be deemed important.
It is standard practice in software development to tag versions
using semantic versioning e.g. `v1.0.5` the same style may be, and often is (REF) used for scientific workflows.
The metadata describing the significance of a tag may be of more importance,
this could include a high-level description of the changes introduced to code
but also scientific context relevant to these changes.

The concept of GitHub releases extends that of git tags such that extra information and data can be included.
In addition to capturing a snapshot of code used to generate some results we are able to capture
workflow run metadata and the generated results.
GitHub does not limit the total size of binary release files,
but each individual file must be under 2 GB in size.
Larger result files can be split or GitHub Large File Storage can be used.

Using integration between Zenodo and GitHub where our git repository is hosted,
DOIs are generated for each GitHub release.
The end product is a DOI for the project, but also a DOI for each release.
Given an (optional) authentication token, our workflow, on
completion, using API calls, can create a GitHub release associated with that run,
upload workflow metadata and results and finally trigger DOI minting on Zenodo.

Others can use this functionality by simply forking our repository,
generating an access token in their GitHub account and linking their Zenodo account
with the forked repository.

### Git version control and workflow sharing

Keeping code under version control and tagging notable versions as described above
paves the way to workflow sharing. We already have the code for specific revision
available with execution metadata and the results generated by this run/revision.
The particular revision can be checked-out from the git repository, ready for execution.

Nextflow provides a convenient shorthand for that, where a revision can be
(re-) executed e.g. by specifying, at runtime, a version tag (e.g. `v1.4`).
Nextflow will download the specific revision before executing the workflow.

To allow others to re-run the workflow with minimal effort,
we rely on Nextflow facilitating separation
of workflow logic from execution and software environment.
We  distribute our workflow with several execution profile
configurations which allow for the pipeline to be run on a dedicated server,
a high performance computing (HPC) cluster or in the cloud.
Crucially, the workflow logic remains unchanged while the software environment
is provided either via docker or singularity containers depending on execution
profile used.
Additional execution profiles can be added to accommodate other compute environments.

By far the most portable execution profiles are those relying on public cloud resources.
This facilitates practical reproducibility, allowing anyone with sufficient means
to rent such resources from a cloud provider,
to re-run, confirm or challenge postulated results with negligible effort.

Our `awsbatch` profile requires the user to have and AWS account and
AWS Batch compute environment configured - this is not specific to our workflow
but we document the configuration steps required at
[https://github.com/csiro-crop-informatics/biokanga-manuscript](https://github.com/csiro-crop-informatics/biokanga-manuscript).
The advantage of using this profile is that it allows for workflow execution configuration
to be defined consistently for users who otherwise would only have access to distinct compute environments.
Specific compute instance types (hardware) can be set to facilitate reproducibility although in practice
it might be preferred to allow for heterogeneous composition of compute resources
such that resources use is better optimized and the compute costs are suppressed.

All jobs run on AWS batch must be run in containers, so unlike
in HPC environment where some processes may rely on commonly available tools
pre-installed on the system, we are forced to explicitly configure the software environment.
In conjunction with other practices proposed in this work, this ensures that
a complete record of software used is preserved and readily available for re-use.

# Reproducibility overhead

Building workflows for reproducibility creates a number of challenges for the developer,
depending on developer's past experience and expertise these may include the need for mastering
new concepts, new tools and potentially also a new programming language at least up to a point
required to glue scripts and programs into a coherent whole.

Containerisation of software environment means that some of system administration responsibilities
are effectively transferred to the developer who, for example, needs to ensure that the entire tool-set
required for a given task is included in the container.
This may include software tools which we take for granted in a HPC environment but may not be available
in source images commonly used for building custom containers.

Portability of workflows across execution environment can be difficult to achieve.
Main risks lie in the ease of a quick and often compute-specific solutions to problems arising in the development.
Nextflow enables the separation of workflow logic and configuration but it is not enforced as this would
be detrimental to flexibility and usability of the system.
Given execution environments may pose some constraints which have to be addressed and as a result,
additional code is required to ensure that workflow behaviour conforms to those constraints.
For example, when running the workflow in the cloud (AWS Batch), input/output locations for data and workflow metadata
have to be handled differently the in the case of a HPC cluster.
This is done seamlessly by our workflow, but required additional time invested upfront to develop and test
an appropriate configuration.

Although substantial, all these overheads can be seen as investments.
Carefully designed portable workflow configuration can be easily re-used
such that subsequent workflows can be developed much quicker.
The container images tagged with respective tool versions and commit SHA hashes
are freely available, so anyone who needs to use the specific version of a tool,
can simply point to an image in their workflow definition or pull, build and use the  container directly.


* consider also modularity
  * NF under dev
  * Snakemake wrappers
















## describe workflow

### Use of containers

The workflow relies on multiple containers executed either through Docker or Singularity.
Core to the workflow design is having a separate container for each aligner.
Additional containers provide the tool-sets required to pre- post-process data
and evaluate results. For example the RNFtools container is used to simulate
the DNA-Seq reads and later to evaluate the alignment results.



## describe biokanga align

# Results

- show benchmark outputs
- nextflow graph?

# Discussion

- Use of a framework such as this allows for straightforward and consistent deployment of analytical code and tools
- Clarity around which version and environment was used to produce a particular artefact/output
- extensible (guide for adding an aligner is clear)
- biokanga is a reasonable option as an aligner

# Conclusion

- A comprehensive approach such as the one presented here requires a non-trivial amount of overhead
- The advantages are significant
- The framework can be reused very simply (the overhead doesn't need to be spent by someone else)
- Methodology developed e.g. for container version tracking and deployment can easily be applied elsewhere.

[//]: # (Cite papers like this: `[@Kim2015]` [@Kim2015; @Baruzzo2016] matching entries in `references.bib`.)



## Real RNA-Seq data

In addition to the simulation-based evaluation, our pipeline includes an execution path where real reads are aligned using exactly the same tools, indices and parametrisation as in the case of the simulation experiments.
In this case we are unable to evaluate the correctness in terms of read mapping locations but these results provide more realistic run-time comparison independent of potential artifacts introduced by read simulation.
In addition, considering reported alignments of real data alongside a given tool's accuracy measures provides some perspective for interpreting

* alignment rates reported by a given aligner
* consistency of some of simulation-based results with those obtained using real reads


# Acknowledgements {-}

[https://github.com/Robinlovelace/rmarkdown-paper-repo](https://github.com/Robinlovelace/rmarkdown-paper-repo)

# References

